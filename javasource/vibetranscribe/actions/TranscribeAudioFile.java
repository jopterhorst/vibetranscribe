// This file was generated by Mendix Studio Pro.
//
// WARNING: Only the following code will be retained when actions are regenerated:
// - the import list
// - the code between BEGIN USER CODE and END USER CODE
// - the code between BEGIN EXTRA CODE and END EXTRA CODE
// Other code you write will be lost the next time you deploy the project.
// Special characters, e.g., é, ö, à, etc. are supported in comments.

package vibetranscribe.actions;

import com.mendix.systemwideinterfaces.core.IContext;
import com.mendix.systemwideinterfaces.core.IMendixObject;
import com.mendix.systemwideinterfaces.core.UserAction;
import org.vosk.LibVosk;
import org.vosk.LogLevel;
import org.vosk.Model;
import org.vosk.Recognizer;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import java.io.InputStream;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.File;
import com.mendix.logging.ILogNode;
import com.mendix.core.Core;

public class TranscribeAudioFile extends UserAction<java.lang.String>
{
	/** @deprecated use Parameter.getMendixObject() instead. */
	@java.lang.Deprecated(forRemoval = true)
	private final IMendixObject __Parameter;
	private final system.proxies.FileDocument Parameter;

	public TranscribeAudioFile(
		IContext context,
		IMendixObject _parameter
	)
	{
		super(context);
		this.__Parameter = _parameter;
		this.Parameter = _parameter == null ? null : system.proxies.FileDocument.initialize(getContext(), _parameter);
	}

	@java.lang.Override
	public java.lang.String executeAction() throws Exception
	{
		// BEGIN USER CODE
		long startTime = System.currentTimeMillis();
		logger.info("Starting Vosk transcription: " + (Parameter != null ? Parameter.getName() : "unknown file"));
		
		if (Parameter == null || !Parameter.getHasContents()) {
			logger.error("No audio file provided");
			throw new com.mendix.systemwideinterfaces.MendixRuntimeException("No audio file provided or file is empty");
		}

		String fileName = Parameter.getName();
		
		// Validate audio format
		if (!isValidAudioFormat(fileName)) {
			logger.warn("Non-WAV format detected: " + fileName + " - Vosk works best with WAV files");
		}

		try {
			// Set Vosk log level
			LibVosk.setLogLevel(LogLevel.WARNINGS);
			
			// Initialize Vosk model
			String modelPath = getModelPath();
			logger.info("Loading Vosk model from: " + modelPath);
			
			Model model = new Model(modelPath);
			Recognizer recognizer = new Recognizer(model, 16000);
			
			// Get the audio file content as byte array
			ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
			Parameter.getContents(getContext(), outputStream);
			byte[] audioBytes = outputStream.toByteArray();
			
			// Analyze and convert audio if needed
			audioBytes = analyzeAndConvertAudio(audioBytes, fileName);
			
			// Create input stream and skip WAV header if present
			InputStream audioStream = new ByteArrayInputStream(audioBytes);
			if (audioBytes.length > 44 && isWavFile(audioBytes)) {
				audioStream.skip(44); // Skip WAV header
				logger.info("Skipped WAV header for processing");
			}
			
			// Process audio in chunks for Vosk
			byte[] buffer = new byte[4096];
			int bytesRead;
			StringBuilder transcriptionResult = new StringBuilder();
			ObjectMapper mapper = new ObjectMapper();
			
			while ((bytesRead = audioStream.read(buffer)) != -1) {
				if (recognizer.acceptWaveForm(buffer, bytesRead)) {
					String result = recognizer.getResult();
					JsonNode resultJson = mapper.readTree(result);
					String text = resultJson.get("text").asText();
					if (!text.trim().isEmpty()) {
						if (transcriptionResult.length() > 0) {
							transcriptionResult.append(" ");
						}
						transcriptionResult.append(text.trim());
						logger.debug("Partial result: " + text);
					}
				}
			}
			
			// Get final result
			String finalResult = recognizer.getFinalResult();
			JsonNode finalJson = mapper.readTree(finalResult);
			String finalText = finalJson.get("text").asText();
			if (!finalText.trim().isEmpty()) {
				if (transcriptionResult.length() > 0) {
					transcriptionResult.append(" ");
				}
				transcriptionResult.append(finalText.trim());
			}
			
			// Clean up resources
			audioStream.close();
			outputStream.close();
			recognizer.close();
			model.close();
			
			// Calculate timing
			long endTime = System.currentTimeMillis();
			double transcriptionTimeSeconds = (endTime - startTime) / 1000.0;
			
			String finalTranscription = transcriptionResult.toString().trim();
			
			if (finalTranscription.isEmpty()) {
				logger.warn("No speech detected in audio file");
				logger.info("Vosk transcription completed in " + String.format("%.2f", transcriptionTimeSeconds) + " seconds");
				return "No speech detected in the audio file. Please ensure the audio contains clear speech and is in WAV format (16kHz, 16-bit, mono recommended).";
			}
			
			logger.info("Vosk transcription completed successfully in " + String.format("%.2f", transcriptionTimeSeconds) + " seconds");
			logger.info("Final result: '" + finalTranscription + "' (" + finalTranscription.length() + " chars)");
			
			return finalTranscription;
			
		} catch (Exception e) {
			logger.error("Vosk transcription failed: " + e.getMessage(), e);
			throw new com.mendix.systemwideinterfaces.MendixRuntimeException(
				"Error during Vosk audio transcription: " + e.getMessage() + 
				". Please ensure the audio file is in a supported format and the Vosk model is properly installed.", e);
		}
		// END USER CODE
	}

	/**
	 * Returns a string representation of this action
	 * @return a string representation of this action
	 */
	@java.lang.Override
	public java.lang.String toString()
	{
		return "TranscribeAudioFile";
	}

	// BEGIN EXTRA CODE
	private static final ILogNode logger = Core.getLogger("VibeTranscribe");
	
	/**
	 * Get the path to the Vosk model directory
	 */
	private String getModelPath() {
		// Try different possible locations for the model
		String[] possiblePaths = {
			"resources/vibetranscribe/vosk-model-small-en-us-0.15",
			"./resources/vibetranscribe/vosk-model-small-en-us-0.15",
			"../resources/vibetranscribe/vosk-model-small-en-us-0.15",
			System.getProperty("user.dir") + "/resources/vibetranscribe/vosk-model-small-en-us-0.15",
			"userlib/vosk-model-small-en-us-0.15",
			"./userlib/vosk-model-small-en-us-0.15",
			"../userlib/vosk-model-small-en-us-0.15",
			System.getProperty("user.dir") + "/userlib/vosk-model-small-en-us-0.15"
		};
		
		for (String path : possiblePaths) {
			File modelDir = new File(path);
			if (modelDir.exists() && modelDir.isDirectory()) {
				logger.info("Found Vosk model at: " + modelDir.getAbsolutePath());
				return modelDir.getAbsolutePath();
			}
		}
		
		// Default fallback - prefer resources/vibetranscribe location
		logger.warn("Model not found in standard locations, using default resources path");
		return "resources/vibetranscribe/vosk-model-small-en-us-0.15";
	}
	
	/**
	 * Check if the byte array represents a WAV file
	 */
	private boolean isWavFile(byte[] audioBytes) {
		if (audioBytes.length < 12) return false;
		
		String riffHeader = new String(audioBytes, 0, 4);
		String waveHeader = new String(audioBytes, 8, 4);
		
		return "RIFF".equals(riffHeader) && "WAVE".equals(waveHeader);
	}
	
	/**
	 * Validates if the audio file format is supported by Vosk
	 * Vosk works best with WAV files at 16kHz, 16-bit, mono
	 */
	private boolean isValidAudioFormat(String fileName) {
		if (fileName == null) {
			return false;
		}
		String extension = fileName.toLowerCase();
		boolean isValid = extension.endsWith(".wav") || extension.endsWith(".wave");
		if (!isValid) {
			logger.warn("Non-WAV format detected: " + fileName + " - Vosk works best with WAV files");
		}
		return isValid;
	}
	
	/**
	 * Analyzes audio and converts to 16kHz mono if needed
	 */
	private byte[] analyzeAndConvertAudio(byte[] audioBytes, String fileName) {
		if (audioBytes.length < 44) {
			logger.warn("File too small to be valid WAV: " + fileName);
			return audioBytes;
		}
		
		// Check for WAV header and extract format info
		if (isWavFile(audioBytes)) {
			try {
				// Extract key audio parameters
				int sampleRate = ((audioBytes[27] & 0xFF) << 24) | 
								((audioBytes[26] & 0xFF) << 16) | 
								((audioBytes[25] & 0xFF) << 8) | 
								(audioBytes[24] & 0xFF);
				int channels = ((audioBytes[23] & 0xFF) << 8) | (audioBytes[22] & 0xFF);
				int formatCode = ((audioBytes[21] & 0xFF) << 8) | (audioBytes[20] & 0xFF);
				
				logger.info("Audio format: " + sampleRate + "Hz, " + channels + " channels, format code: " + formatCode);
				
				// Check if conversion is needed
				if (formatCode != 1) {
					logger.error("CRITICAL: Audio is not PCM format (code: " + formatCode + ") - Vosk requires PCM");
					return audioBytes;
				} else if (sampleRate != 16000 || channels != 1) {
					logger.info("Converting audio from " + sampleRate + "Hz (" + channels + " ch) to 16kHz mono for optimal Vosk performance");
					return convertAudioTo16kHz(audioBytes, sampleRate, channels);
				} else {
					logger.info("Audio format is already optimal for Vosk transcription");
					return audioBytes;
				}
			} catch (Exception e) {
				logger.warn("Could not analyze WAV format details: " + e.getMessage());
				return audioBytes;
			}
		} else {
			logger.error("Not a WAV file - Vosk works best with WAV format");
			return audioBytes;
		}
	}
	
	/**
	 * Converts audio to 16kHz mono format for optimal Vosk performance
	 */
	private byte[] convertAudioTo16kHz(byte[] audioBytes, int originalSampleRate, int channels) {
		if (originalSampleRate == 16000 && channels == 1) {
			return audioBytes; // Already optimal
		}
		
		try {
			int headerSize = 44; // WAV header size
			int dataSize = audioBytes.length - headerSize;
			
			// Calculate conversion ratio
			double ratio = (double) originalSampleRate / 16000.0;
			int originalSamples = dataSize / (channels * 2); // 16-bit = 2 bytes per sample
			int newSamples = (int) (originalSamples / ratio);
			int newDataSize = newSamples * 2; // mono 16-bit
			
			byte[] converted = new byte[headerSize + newDataSize];
			
			// Copy and modify WAV header
			System.arraycopy(audioBytes, 0, converted, 0, headerSize);
			
			// Update file size (bytes 4-7)
			int newFileSize = headerSize + newDataSize - 8;
			converted[4] = (byte) (newFileSize & 0xFF);
			converted[5] = (byte) ((newFileSize >> 8) & 0xFF);
			converted[6] = (byte) ((newFileSize >> 16) & 0xFF);
			converted[7] = (byte) ((newFileSize >> 24) & 0xFF);
			
			// Update sample rate (bytes 24-27)
			converted[24] = (byte) (16000 & 0xFF);
			converted[25] = (byte) ((16000 >> 8) & 0xFF);
			converted[26] = (byte) ((16000 >> 16) & 0xFF);
			converted[27] = (byte) ((16000 >> 24) & 0xFF);
			
			// Update channels to mono (bytes 22-23)
			converted[22] = 1;
			converted[23] = 0;
			
			// Update byte rate (bytes 28-31): sample_rate * channels * bits_per_sample / 8
			int byteRate = 16000 * 1 * 16 / 8;
			converted[28] = (byte) (byteRate & 0xFF);
			converted[29] = (byte) ((byteRate >> 8) & 0xFF);
			converted[30] = (byte) ((byteRate >> 16) & 0xFF);
			converted[31] = (byte) ((byteRate >> 24) & 0xFF);
			
			// Update block align (bytes 32-33): channels * bits_per_sample / 8
			converted[32] = 2; // 1 channel * 16 bits / 8 = 2
			converted[33] = 0;
			
			// Update data chunk size (bytes 40-43)
			converted[40] = (byte) (newDataSize & 0xFF);
			converted[41] = (byte) ((newDataSize >> 8) & 0xFF);
			converted[42] = (byte) ((newDataSize >> 16) & 0xFF);
			converted[43] = (byte) ((newDataSize >> 24) & 0xFF);
			
			// Convert audio data with downsampling
			for (int i = 0; i < newSamples; i++) {
				int originalIndex = (int) (i * ratio);
				int sourceOffset = headerSize + (originalIndex * channels * 2);
				
				if (sourceOffset + 1 < audioBytes.length) {
					short sample;
					
					if (channels == 2) {
						// Convert stereo to mono by averaging left and right channels
						if (sourceOffset + 3 < audioBytes.length) {
							short leftSample = (short) (((audioBytes[sourceOffset + 1] & 0xFF) << 8) | (audioBytes[sourceOffset] & 0xFF));
							short rightSample = (short) (((audioBytes[sourceOffset + 3] & 0xFF) << 8) | (audioBytes[sourceOffset + 2] & 0xFF));
							sample = (short) ((leftSample + rightSample) / 2);
						} else {
							sample = (short) (((audioBytes[sourceOffset + 1] & 0xFF) << 8) | (audioBytes[sourceOffset] & 0xFF));
						}
					} else {
						// Already mono, just downsample
						sample = (short) (((audioBytes[sourceOffset + 1] & 0xFF) << 8) | (audioBytes[sourceOffset] & 0xFF));
					}
					
					// Write the converted sample
					converted[headerSize + i * 2] = (byte) (sample & 0xFF);
					converted[headerSize + i * 2 + 1] = (byte) ((sample >> 8) & 0xFF);
				}
			}
			
			logger.info("Audio successfully converted from " + originalSampleRate + "Hz (" + channels + " ch) to 16kHz mono for Vosk");
			return converted;
			
		} catch (Exception e) {
			logger.warn("Audio conversion failed, using original: " + e.getMessage());
			return audioBytes;
		}
	}
	// END EXTRA CODE
}
